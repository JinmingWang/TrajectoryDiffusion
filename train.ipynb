{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.DidiDataset import DidiTrajectoryDataset, collectFunc\n",
    "from Models.TrajUNet import TrajUNet\n",
    "from DiffusionManager import DiffusionManager\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_length = 120\n",
    "dataset_root = 'E:/Data/Didi/xian/nov'\n",
    "\n",
    "stem_channels = 32\n",
    "num_blocks = 4\n",
    "max_diffusion_step = 300\n",
    "res_blocks = 2\n",
    "min_beta = 0.0001\n",
    "max_beta = 0.005\n",
    "\n",
    "init_lr = 1e-3\n",
    "\n",
    "files_per_part = 2\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DidiTrajectoryDataset(dataset_root, traj_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrajUNet(stem_channels, max_diffusion_step, num_blocks, res_blocks)\n",
    "diff_manager = DiffusionManager(min_beta, max_beta, max_diffusion_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    n_files_load = 0\n",
    "    totla_num_files = dataset.num_files\n",
    "    while dataset.loadNextParts(files_per_part):\n",
    "        n_files_load  = min(n_files_load + files_per_part, totla_num_files)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collectFunc)\n",
    "        for traj_0, attr in tqdm(dataloader, desc=f'Epoch {e} File {n_files_load}/{totla_num_files}'):\n",
    "            # Diffusion forward\n",
    "            t = torch.randint(0, max_diffusion_step, (traj_0.shape[0],)).cuda()\n",
    "            epsilon = torch.randn_like(traj_0).cuda()\n",
    "            traj_t = diff_manager.diffusionForward(traj_0, t, epsilon)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            epsilon_pred = model(traj_t, t, attr)\n",
    "            loss = loss_func(epsilon_pred, epsilon)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
