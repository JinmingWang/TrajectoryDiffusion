{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/TrajectoryDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Dataset.DidiDataset import DidiTrajectoryDataset, collectFunc\n",
    "from Models.TrajUNet import TrajUNet\n",
    "from DiffusionManager import DiffusionManager\n",
    "from Utils import MovingAverage, saveModel, loadModel, exportONNX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "from os import makedirs\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chengdu_nov_dataset_args = {\n",
    "    \"dataset_root\": \"E:/Data/Didi/chengdu/nov\",\n",
    "    \"traj_length\": 200,\n",
    "    \"feature_mean\": [21599.4980, 104.0789535914567, 30.680879399098956],    # time lon lat\n",
    "    \"feature_std\": [12470.9102, 0.0032705687484356773, 0.018204423046522103],\n",
    "}\n",
    "\n",
    "xian_nov_dataset_args = {\n",
    "    \"dataset_root\": \"E:/Data/Didi/xian/nov\",\n",
    "    \"traj_length\": 200,\n",
    "    \"feature_mean\": [21599.4980, 108.950773428688, 34.24354179925547],    # time lon lat\n",
    "    \"feature_std\": [12470.9102, 0.02129110045580343, 0.019358855648211895],\n",
    "}\n",
    "\n",
    "diffusion_args = {\n",
    "    \"min_beta\": 0.0001,\n",
    "    \"max_beta\": 0.05,\n",
    "    \"max_diffusion_step\": 500,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    \"channel_schedule\": [128, 128, 256, 512, 1024],\n",
    "    \"diffusion_steps\": diffusion_args[\"max_diffusion_step\"],\n",
    "    \"res_blocks\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "init_lr = 1e-3\n",
    "lr_reduce_factor = 0.5\n",
    "lr_reduce_patience = 2000\n",
    "\n",
    "# Colab can have 51GB RAM or 12.7GB RAM, GPU is Tesla T4 which has 15GB RAM\n",
    "files_per_part = 2\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "log_interval = 100\n",
    "save_interval = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DidiTrajectoryDataset(**xian_nov_dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrajUNet(**model_args).cuda()\n",
    "model.train()\n",
    "diff_manager = DiffusionManager(**diffusion_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=lr_reduce_factor, patience=lr_reduce_patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "makedirs(f\"Runs/{start_time}\")\n",
    "writer = SummaryWriter(f\"Runs/{start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "If your memory >= 16GB, you can load the dataset in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading E:/Data/Didi/xian/nov\\gps_20161101.pt\n",
      "Loading E:/Data/Didi/xian/nov\\gps_20161102.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loadNextFiles(dataset.n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Projects\\TrajectoryDiffusion\\train.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(traj[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu(), traj[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu(), color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msolid\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, markersize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m visualizeTraj(dataset[\u001b[39m3\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32me:\\Projects\\TrajectoryDiffusion\\Dataset\\DidiDataset.py:103\u001b[0m, in \u001b[0;36mDidiTrajectoryDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m    :param index: The index of the trajectory in dataset_part\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    :return: lon_lat: (2, N), attr: (3,), times: (N,)\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     lon_lat, times \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_part[index]\n\u001b[0;32m    104\u001b[0m     times \u001b[39m=\u001b[39m (times\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraj_mean[:, \u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraj_std[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m    106\u001b[0m     traj_length \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39msum((lon_lat[\u001b[39m1\u001b[39m:] \u001b[39m-\u001b[39m lon_lat[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39msum()   \u001b[39m# the length of the trajectory\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualizeTraj(traj: torch.Tensor) -> None:\n",
    "    \"\"\" draw trajectory\n",
    "\n",
    "    :param traj: trajectory to draw, shape: (2, N) for lat lon\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.plot(traj[0].detach().cpu(), traj[1].detach().cpu(), color='blue', marker='o', linestyle='solid', linewidth=0.5, markersize=1)\n",
    "    plt.show()\n",
    "visualizeTraj(dataset[3][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_it = 0\n",
    "\n",
    "mov_avg_loss = MovingAverage(log_interval)\n",
    "\n",
    "for e in range(epochs):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collectFunc)\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {e}')\n",
    "    for traj_0, attr, times in pbar:\n",
    "        # Diffusion forward\n",
    "        t = torch.randint(0, diffusion_args[\"max_diffusion_step\"], (traj_0.shape[0],)).cuda()\n",
    "        epsilon = torch.randn_like(traj_0).cuda()\n",
    "        traj_t = diff_manager.diffusionForward(traj_0, t, epsilon)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epsilon_pred = model(traj_t, t, attr)\n",
    "        loss = loss_func(epsilon_pred, epsilon)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(float(mov_avg_loss))\n",
    "\n",
    "        global_it += 1\n",
    "        mov_avg_loss << loss.item()\n",
    "        pbar.set_postfix_str(f'Loss: {mov_avg_loss:.5f}')\n",
    "\n",
    "        if global_it % log_interval == 0:\n",
    "            writer.add_scalar('Loss', float(mov_avg_loss), global_it)\n",
    "\n",
    "        if global_it % save_interval == 0:\n",
    "            saveModel(model, f\"Runs/{start_time}/{model.__class__.__name__}_{global_it}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "If your memory < 16GB, you may want to load the dataset in parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading E:/Data/Didi/xian/nov\\gps_20161101.pt\n",
      "Loading E:/Data/Didi/xian/nov\\gps_20161102.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 File 2/30:  11%|█▏        | 277/2457 [00:29<03:54,  9.29it/s, Loss: 0.97250]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Projects\\TrajectoryDiffusion\\train.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m epsilon_pred \u001b[39m=\u001b[39m model(traj_t, t, attr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(epsilon_pred, epsilon)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/TrajectoryDiffusion/train.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep(\u001b[39mfloat\u001b[39m(mov_avg_loss))\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_it = 0\n",
    "\n",
    "mov_avg_loss = MovingAverage(log_interval)\n",
    "\n",
    "for e in range(epochs):\n",
    "    n_files_load = 0\n",
    "    total_num_files = dataset.n_files\n",
    "    while dataset.loadNextFiles(files_per_part):\n",
    "        n_files_load  = min(n_files_load + files_per_part, total_num_files)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collectFunc)\n",
    "        pbar = tqdm(dataloader, desc=f'Epoch {e} File {n_files_load}/{total_num_files}')\n",
    "        for traj_0, attr, times in pbar:\n",
    "            # Diffusion forward\n",
    "            t = torch.randint(0, diffusion_args[\"max_diffusion_step\"], (traj_0.shape[0],)).cuda()\n",
    "            epsilon = torch.randn_like(traj_0).cuda()\n",
    "            traj_t = diff_manager.diffusionForward(traj_0, t, epsilon)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            epsilon_pred = model(traj_t, t, attr)\n",
    "            loss = loss_func(epsilon_pred, epsilon)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(float(mov_avg_loss))\n",
    "\n",
    "            global_it += 1\n",
    "            mov_avg_loss << loss.item()\n",
    "            pbar.set_postfix_str(f'Loss: {mov_avg_loss:.5f}')\n",
    "\n",
    "            if global_it % log_interval == 0:\n",
    "                writer.add_scalar('Loss', float(mov_avg_loss), global_it)\n",
    "\n",
    "            if global_it % save_interval == 0:\n",
    "                saveModel(model, f\"Runs/{start_time}/{model.__class__.__name__}_{global_it}.pth\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
